{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open csv, drop unnecessary columns\n",
    "nba = pd.read_csv(\"../nba.csv\")\n",
    "nba = nba.drop(columns = [\"Unnamed: 6\", \"Start (ET)\",\"Notes\",\"Unnamed: 7\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean date and turn to date_time type\n",
    "nba.Date = nba.Date.str.replace(\"^[A-z]{3}\",\"-\")\n",
    "nba.Date.str.lstrip(\"- \")\n",
    "nba.Date = nba.Date.str.replace(\" \",\"-\").str.lstrip(\"-\")\n",
    "nba.Date = pd.to_datetime(nba.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming columns\n",
    "nba = nba.rename(columns = {\"PTS\":\"AwayPTS\", \"PTS.1\":\"HomePTS\", \"Visitor/Neutral\":\"Away\",\"Home/Neutral\":\"Home\", \"Attend.\":\"Attend\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating homewins columns\n",
    "nba[\"HomeWin\"] = np.where(nba[\"HomePTS\"] > nba[\"AwayPTS\"], 1,0)\n",
    "#nba.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbatest = nba[[\"Away\",\"Home\",\"HomeWin\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "dummies = pd.get_dummies(nbatest[[\"Away\",\"Home\"]])\n",
    "nbatest[dummies.columns] = dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbatest = nbatest.drop(columns = [\"Home\",\"Away\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining functions that check the accuracy score of our predictions using different models\n",
    "#Random Forests\n",
    "def RFscore(nbatest):\n",
    "    X_train = nbatest[:900].drop(columns = \"HomeWin\")    \n",
    "    y_train = nbatest[\"HomeWin\"][:900]\n",
    "    X_test = nbatest[900:].drop(columns = \"HomeWin\")\n",
    "    y_test = nbatest[\"HomeWin\"][900:]\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.datasets import make_classification\n",
    "    mod = RandomForestClassifier(n_estimators = 100)\n",
    "    mod.fit(X_train, y_train)\n",
    "    y_pred = mod.predict(X_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    return accuracy_score(y_test,y_pred)\n",
    "\n",
    "\n",
    "#SVC\n",
    "def SVCscore(nbatest):\n",
    "    #train data/ test data\n",
    "    X_train = nbatest[:900].drop(columns = \"HomeWin\")    \n",
    "    y_train = nbatest[\"HomeWin\"][:900]\n",
    "    X_test = nbatest[900:].drop(columns = \"HomeWin\")\n",
    "    y_test = nbatest[\"HomeWin\"][900:]\n",
    "    \n",
    "    #fit model\n",
    "    from sklearn.svm import SVC\n",
    "    svc = SVC(gamma='auto')\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    return accuracy_score(y_test,y_pred)\n",
    "\n",
    "\n",
    "#LogisticRegression\n",
    "def LRscore(nbatest):\n",
    "    X_train = nbatest[:900].drop(columns = \"HomeWin\")    \n",
    "    y_train = nbatest[\"HomeWin\"][:900]\n",
    "    X_test = nbatest[900:].drop(columns = \"HomeWin\")\n",
    "    y_test = nbatest[\"HomeWin\"][900:]\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    mod = LogisticRegression()\n",
    "    mod.fit(X_train,y_train)\n",
    "    y_pred = mod.predict(X_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    return accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding \"time on the road\" feature\n",
    "nbatest[\"Timeaway\"] = 0\n",
    "away_counts = {}\n",
    "for i in nba[\"Away\"].unique():\n",
    "    away_counts[i] = 0\n",
    "for i in range(len(nba.Away)):\n",
    "    away_counts[nba.Away[i]] +=1\n",
    "    away_counts[nba.Home[i]] = 0\n",
    "    nbatest.iloc[i,-1] = away_counts[nba.Away[i]]\n",
    "\n",
    "print(\"Logistic Regression Accuracy Score: \",LRscore(nbatest),\"\\nSVC Accuracy score:\",SVCscore(nbatest),\"\\nRandom Forests Accuracy score:\",RFscore(nbatest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding Home win streak and Away win streak features\n",
    "nbatest[\"HomeStreak\"] = 0\n",
    "nbatest[\"AwayStreak\"] = 0\n",
    "win_counts = {}\n",
    "for i in nba[\"Away\"].unique():\n",
    "    win_counts[i] = 0\n",
    "    \n",
    "for row in range(len(nba)):\n",
    "    if nbatest[\"HomeWin\"][row] == 1:\n",
    "        win_counts[nba[\"Home\"][row]] +=1\n",
    "        win_counts[nba[\"Away\"][row]] == 0\n",
    "    else:\n",
    "        win_counts[nba[\"Away\"][row]] +=1\n",
    "        win_counts[nba[\"Home\"][row]] == 0\n",
    "    nbatest.iloc[row,-2] = win_counts[nba[\"Home\"][row]]\n",
    "    nbatest.iloc[row,-1] = win_counts[nba[\"Away\"][row]]\n",
    "    \n",
    "print(\"Logistic Regression Accuracy Score: \",LRscore(nbatest),\"\\nSVC Accuracy score:\",SVCscore(nbatest),\"\\nRandom Forests Accuracy score:\",RFscore(nbatest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANKINGS\n",
    "#Creates dictionary with team and their rankings\n",
    "feb_ranks = pd.read_csv(\"feb_ranks.csv\")\n",
    "feb_ranks[\"Team\"] = feb_ranks[\"Western Conference\"]\n",
    "rankdict = {}\n",
    "for i in range(len(feb_ranks.Team)):\n",
    "    rankdict[feb_ranks.Team[i]] = feb_ranks.Rk[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates HomeRank and AwayRank for each matchup in nba dataset\n",
    "nbatest[\"HomeRank\"] = 0\n",
    "nbatest[\"AwayRank\"] = 0\n",
    "for i in range(len(nbatest.HomeRank)):\n",
    "    #Setting AwayRank for row i\n",
    "    nbatest.iloc[i,-1] = rankdict[nba.Away[i]]\n",
    "    #Setting HomeRank for row i\n",
    "    nbatest.iloc[i,-2] = rankdict[nba.Home[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankspread = nbatest[\"HomeRank\"]-nbatest[\"AwayRank\"]\n",
    "nbatest[\"HomeRanksHigher\"]= 0\n",
    "#if rankspread is positive, home is better\n",
    "#if rankspread is negative, away is better\n",
    "for i in range(len(nbatest)):\n",
    "    if rankspread[i] > 0:\n",
    "        nbatest.iloc[i,-1] = 1\n",
    "    else:\n",
    "        nbatest.iloc[i,-1] = 0\n",
    "        \n",
    "\n",
    "print(\"Logistic Regression Accuracy Score: \",LRscore(nbatest),\"\\nSVC Accuracy score:\",SVCscore(nbatest),\"\\nRandom Forests Accuracy score:\",RFscore(nbatest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankspread = nbatest[\"HomeRank\"]-nbatest[\"AwayRank\"]\n",
    "nbatest[\"HomeisFav\"]= 0\n",
    "for i in range(len(nbatest)):\n",
    "    if rankspread[i] > 0 and rankspread[i] >13:\n",
    "        nbatest.iloc[i,-1] = 1\n",
    "    elif rankspread[i]<0 and abs(rankspread[i])>13:\n",
    "        nbatest.iloc[i,-1] = 0\n",
    "    else:\n",
    "        nbatest.iloc[i,-1] = 0\n",
    "        \n",
    "print(\"Logistic Regression Accuracy Score: \",LRscore(nbatest),\"\\nSVC Accuracy score:\",SVCscore(nbatest),\"\\nRandom Forests Accuracy score:\",RFscore(nbatest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
